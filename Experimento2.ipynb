{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimento 2\n",
    "\n",
    "Jeffrey Leiva Cascante 2021016720\n",
    "\n",
    "Richard Le√≥n Chinchilla 2019003759\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import hydra\n",
    "from Config.config import Configuration\n",
    "from DenoisingAutoencoder import DenoisingAutoEncoder\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import transforms, datasets\n",
    "import pytorch_lightning as L\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from DataModule import ButterflyDataModule\n",
    "import wandb\n",
    "import torch\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import io\n",
    "from sklearn.cluster import KMeans\n",
    "from threadpoolctl import threadpool_limits\n",
    "from PIL import Image\n",
    "\n",
    "wandb.login()\n",
    "\n",
    "notebook_dir = os.path.dirname(os.path.abspath(os.getcwd()))\n",
    "config_dir = os.path.join(notebook_dir, 'proyecto-transfer-learning\\\\Config')\n",
    "\n",
    "sys.argv = [arg for arg in sys.argv if not arg.startswith(\"--\")]\n",
    "\n",
    "@hydra.main(config_path=config_dir, config_name=\"config\", version_base=None)\n",
    "def trainining_denoising_autoencoder(config: Configuration):\n",
    "    data_module = ButterflyDataModule(config.DATASET.DATA_DIR,config.TRAIN.BATCH_SIZE, False, 0,\n",
    "                                      config.TRAIN.NUM_WORKERS)\n",
    "    data_module.setup()\n",
    "\n",
    "\n",
    "    model = DenoisingAutoEncoder(config.MODEL.LATENT_DIM,config.TRAIN.LEARNING_RATE)\n",
    "\n",
    "    early_stop_callback = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=3,\n",
    "        verbose=False,\n",
    "        mode='min'\n",
    "    )\n",
    "\n",
    "    wandb_logger = WandbLogger(\n",
    "        project=\"Denoising-Autoencoder\",\n",
    "        log_model=True,\n",
    "    )\n",
    "\n",
    "    trainer = L.Trainer(\n",
    "        max_epochs=config.TRAIN.NUM_EPOCHS,\n",
    "        accelerator=config.TRAIN.ACCELERATION,\n",
    "        precision=config.TRAIN.PRECISION,\n",
    "        callbacks=[early_stop_callback],\n",
    "        logger=wandb_logger,\n",
    "        devices=1 if torch.cuda.is_available() else None\n",
    "    )\n",
    "\n",
    "\n",
    "    trainer.fit(model, data_module)\n",
    "\n",
    "    #Extraer los vectores latentes\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    latent_vectors, labels = extract_latent_vectors(model,data_module.val_dataloader(),device)\n",
    "\n",
    "    #Convertir los tensores a numpy arrays\n",
    "    latent_vectors_np = latent_vectors.cpu().numpy()\n",
    "\n",
    "    #Aplicar t-SNE\n",
    "    tsne = TSNE(n_components=2, random_state=0)\n",
    "    with threadpool_limits(limits=1):\n",
    "        latent_2d = tsne.fit_transform(latent_vectors_np)\n",
    "\n",
    "    #Visualizar el espacio latente\n",
    "    plot_latent_space(latent_2d,labels,\"Espacio Latente con Labels Reales\",logger=wandb_logger)\n",
    "\n",
    "    #Aplicar K-means\n",
    "    n_clusters = len(np.unique(labels)) #Numero de clases\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    cluster_labels = kmeans.fit_predict(latent_vectors_np)\n",
    "\n",
    "    #Visualizar el espacio latente con las etiquetas de los clusters\n",
    "    plot_latent_space(latent_2d,cluster_labels,\"Espacio Latente con Labels de Clusters\",logger=wandb_logger)\n",
    "\n",
    "    #Finalizar el experimento de wandb\n",
    "\n",
    "    wandb_logger.experiment.finish()\n",
    "\n",
    "# Funcion para extraer los vectores latentes\n",
    "def extract_latent_vectors(model,dataloader,device):\n",
    "        latent_vectors = []\n",
    "        labels = []\n",
    "        with torch.no_grad():\n",
    "            for x, y in dataloader:\n",
    "                x = x.to(device)\n",
    "                z = model.encode(x)\n",
    "                latent_vectors.append(z.cpu())\n",
    "                labels.append(y)\n",
    "        latent_vectors = torch.cat(latent_vectors)\n",
    "        labels = torch.cat(labels)\n",
    "        return latent_vectors, labels.cpu().numpy()\n",
    "\n",
    "def plot_latent_space(latent_2d,labels=None,title=\"Espacio Latente\",logger=None):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    if labels is not None:\n",
    "        scatter = plt.scatter(latent_2d[:,0],latent_2d[:,1],c=labels,cmap='tab10')\n",
    "        unique_labels = np.unique(labels).tolist()\n",
    "        plt.legend(handles=scatter.legend_elements()[0],labels=unique_labels)\n",
    "    else:\n",
    "        plt.scatter(latent_2d[:,0],latent_2d[:,1],alpha=0.7)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Componente 1\")\n",
    "    plt.ylabel(\"Componente 2\")\n",
    "    if logger is not None:\n",
    "        #Guardar la imagen en un buffer\n",
    "        buf = io.BytesIO()\n",
    "        plt.savefig(buf,format='png')\n",
    "        buf.seek(0)\n",
    "        #Convertir el buffer en una imagen de PIL\n",
    "        image = Image.open(buf)\n",
    "\n",
    "        #Subir la imagen a wandb\n",
    "        wandb_image = wandb.Image(image,caption=title)\n",
    "        logger.experiment.log({title:wandb_image})\n",
    "    else:\n",
    "        plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "trainining_denoising_autoencoder()\n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
