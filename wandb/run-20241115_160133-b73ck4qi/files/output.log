LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name    | Type    | Params | Mode
--------------------------------------------
0 | encoder | Encoder | 18.8 M | train
1 | decoder | Decoder | 4.7 M  | train
2 | loss_fn | MSELoss | 0      | train
--------------------------------------------
23.6 M    Trainable params
0         Non-trainable params
23.6 M    Total params
94.369    Total estimated model params size (MB)
47        Modules in train mode
0         Modules in eval mode
Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]
c:\ProgramData\miniconda3\Lib\site-packages\pytorch_lightning\trainer\connectors\data_connector.py:419: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.
Error executing job with overrides: []
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Temp\ipykernel_37280\3955125747.py", line 32, in trainining_autoencoder_ninety_10
    trainer.fit(autoencoder,train_dataloaders=data_manager.unsupervised_train_loader(),
  File "c:\ProgramData\miniconda3\Lib\site-packages\pytorch_lightning\trainer\trainer.py", line 538, in fit
    call._call_and_handle_interrupt(
  File "c:\ProgramData\miniconda3\Lib\site-packages\pytorch_lightning\trainer\call.py", line 47, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\ProgramData\miniconda3\Lib\site-packages\pytorch_lightning\trainer\trainer.py", line 574, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "c:\ProgramData\miniconda3\Lib\site-packages\pytorch_lightning\trainer\trainer.py", line 981, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "c:\ProgramData\miniconda3\Lib\site-packages\pytorch_lightning\trainer\trainer.py", line 1023, in _run_stage
    self._run_sanity_check()
  File "c:\ProgramData\miniconda3\Lib\site-packages\pytorch_lightning\trainer\trainer.py", line 1052, in _run_sanity_check
    val_loop.run()
  File "c:\ProgramData\miniconda3\Lib\site-packages\pytorch_lightning\loops\utilities.py", line 178, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\ProgramData\miniconda3\Lib\site-packages\pytorch_lightning\loops\evaluation_loop.py", line 135, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)
  File "c:\ProgramData\miniconda3\Lib\site-packages\pytorch_lightning\loops\evaluation_loop.py", line 396, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\ProgramData\miniconda3\Lib\site-packages\pytorch_lightning\trainer\call.py", line 319, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "c:\ProgramData\miniconda3\Lib\site-packages\pytorch_lightning\strategies\strategy.py", line 411, in validation_step
    return self.lightning_module.validation_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "e:\proyecto-transfer-learning\AutoencoderU.py", line 85, in validation_step
    x_hat = self(x)
            ^^^^^^^
  File "c:\ProgramData\miniconda3\Lib\site-packages\torch\nn\modules\module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\ProgramData\miniconda3\Lib\site-packages\torch\nn\modules\module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "e:\proyecto-transfer-learning\AutoencoderU.py", line 74, in forward
    return self.decoder(enc_output,skips)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\ProgramData\miniconda3\Lib\site-packages\torch\nn\modules\module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\ProgramData\miniconda3\Lib\site-packages\torch\nn\modules\module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "e:\proyecto-transfer-learning\AutoencoderU.py", line 50, in forward
    dec4 = torch.cat([dec4, skips[2]], 1)   #512x56x56
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Sizes of tensors must match except in dimension 1. Expected size 28 but got size 56 for tensor number 1 in the list.

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
c:\ProgramData\miniconda3\Lib\site-packages\IPython\core\interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.
  warn("To exit: use 'exit', 'quit', or Ctrl-D.", stacklevel=1)
